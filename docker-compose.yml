
services:
  postgres:
    image: debezium/postgres:15
    container_name: postgres_db
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5433:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    command: postgres -c wal_level=logical -c max_replication_slots=10 -c max_wal_senders=10
    restart: always

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://0.0.0.0:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    ports:
      - "9092:9092"
      - "29092:29092"
    depends_on:
      - zookeeper

  schema-registry:
    image: confluentinc/cp-schema-registry:latest
    container_name: schema_registry
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: "kafka:9092"
      SCHEMA_REGISTRY_HOST_NAME: "schema-registry"
    ports:
      - "8081:8081"
    depends_on:
      - kafka

  debezium:
    image: debezium/connect:2.5
    container_name: debezium_connect
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: debezium_configs
      OFFSET_STORAGE_TOPIC: debezium_offsets
      STATUS_STORAGE_TOPIC: debezium_status
      KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      KEY_CONVERTER_SCHEMAS_ENABLE: "false"
      VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_REST_ADVERTISED_HOST_NAME: debezium
    ports:
      - "8083:8083"
    depends_on:
      - kafka
      - schema-registry
      - postgres

  connector-init:
    image: curlimages/curl:latest
    container_name: connector_init
    volumes:
      - ./init-connector.sh:/init-connector.sh
    command: ["sh", "/init-connector.sh"]
    depends_on:
      - debezium
      - kafka
      - postgres
  spark:
    image: bitnami/spark:latest
    container_name: spark
    volumes:
     - ./jars:/opt/spark/jars
     - ./spark_app:/opt/spark_app
    command:
      - "/opt/bitnami/spark/bin/spark-submit"
      - "--packages"
      - "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,io.delta:delta-spark_2.12:3.0.0,org.apache.hadoop:hadoop-aws:3.3.4"
      - "--conf"
      - "spark.driver.memory=2g"
      - "--conf"
      - "spark.executor.memory=2g"     
      - "--conf"
      - "spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension"
      - "--conf"
      - "spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog"
      - "--conf"
      - "spark.hadoop.fs.s3a.access.key=minioadmin"
      - "--conf"
      - "spark.hadoop.fs.s3a.secret.key=minioadmin"
      - "--conf"
      - "spark.hadoop.fs.s3a.endpoint=http://minio:9000"
      - "--conf"
      - "spark.hadoop.fs.s3a.path.style.access=true"
      - "/opt/spark_app/spark_job.py"

    depends_on:
     - kafka
     - minio
    ports:
      - "4040:4040"

  minio:
    image: minio/minio:RELEASE.2024-04-18T19-09-19Z
    container_name: minio
    ports:
      - "9100:9000"
      - "9101:9001"
    volumes:
     - minio-data:/data
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    command: server --console-address ":9001" /data
    restart: unless-stopped


volumes:
  postgres_data:
  minio-data: